# -*- coding: utf-8 -*-
"""LS_NLP_proj_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NFLHKwZeIIZvqPmIsQCx3d0qJHC8vXCD
"""

!pip install nltk gensim scikit-learn

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')

import pandas as pd
import numpy as np
import gensim.downloader as api
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string

df = pd.read_csv('spam_dataset.csv', encoding='latin-1')[['v1', 'v2']]
df.columns = ['Label', 'Message']
df['Label'] = df['Label'].map({'ham': 0, 'spam': 1})

stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    return [word for word in tokens if word.isalpha() and word not in stop_words]

df['Tokens'] = df['Message'].apply(preprocess_text)

w2v_model = api.load('word2vec-google-news-300')

def vectorize(tokens):
    valid_words = [w2v_model[word] for word in tokens if word in w2v_model]
    return np.mean(valid_words, axis=0) if valid_words else np.zeros(300)

df['Vector'] = df['Tokens'].apply(vectorize)

X = np.vstack(df['Vector'].values)
y = df['Label'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)
print("Test Accuracy:", accuracy_score(y_test, clf.predict(X_test)))

def predict_message_class(model, w2v_model, message):
    tokens = preprocess_text(message)
    vector = vectorize(tokens).reshape(1, -1)
    pred = model.predict(vector)[0]
    return 'spam' if pred == 1 else 'ham'

predict_message_class(clf, w2v_model, "hey you won, click here on the link!!!")

